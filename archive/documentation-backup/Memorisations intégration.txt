Rapport Technique d’Intégration Hybride : mem0 + code-graph-rag pour AutoWeave
1. Objectif et Vision

But : Offrir à AutoWeave une mémoire intelligente, hybride, combinant la puissance contextuelle de mem0 et la structure explicable de code-graph-rag (Memgraph), pour des agents IA cloud-native, adaptatifs et auditables.

Enjeux :

    Contextualisation : chaque agent, utilisateur, session a sa propre mémoire persistante, accessible et enrichissable.
    Structuration : l’ensemble du système (agents, workflows, logs, dépendances) est modélisé en graphe pour le raisonnement multi-hop, l’audit, la supervision.
    Scalabilité & Observabilité : intégration Kubernetes, monitoring, logs, alerting.
    Fraîcheur des données : synchronisation, indexation, embeddings à jour.

2. Architecture Hybride Optimisée

┌─────────────────────────────────────────────────────────────────┐
│                    AUTOWEAVE MEMORY LAYER                       │
├─────────────────────────────────────────────────────────────────┤
│  ┌───────────────┐   ┌───────────────┐   ┌───────────────┐      │
│  │   mem0        │   │ code-graph-   │   │  Vector DB    │      │
│  │ (contextuel)  │   │   rag         │   │ (Qdrant/Chroma│      │
│  └───────────────┘   └───────────────┘   └───────────────┘      │
│         │                    │                   │              │
│         └─────────────┬──────┴───────────────┬───┘              │
│                       │                      │                  │
│                AutoWeave Core Engine         │                  │
│                (API, Orchestration)          │                  │
│                       │                      │                  │
│                SillyTavern / Appsmith        │                  │
└─────────────────────────────────────────────────────────────────┘

3. Intégration mem0 (Contextuelle)
Installation & Setup

Dernière version (Juin 2024) :

bash

Copy Code
npm install mem0ai@latest
# ou
pip install mem0ai --upgrade

Extrait de documentation officielle :

    “mem0 is a plug-and-play memory layer for LLM agents, supporting both vector and graph backends. It is designed for multi-user, multi-session, and multi-agent scenarios, with built-in support for Qdrant, Chroma, Pinecone, Neo4j, and Memgraph.”
    — mem0 docs, 2024

Configuration recommandée :

env

Copy Code
MEM0_API_KEY=your_mem0_key
MEM0_VECTOR_STORE=qdrant
MEM0_GRAPH_STORE=memgraph
MEM0_LLM_PROVIDER=openai
MEM0_DEBUG=true

Initialisation Node.js :

js

Copy Code
const { MemoryClient } = require('mem0ai');
const mem0 = new MemoryClient({
  api_key: process.env.MEM0_API_KEY,
  vector_store: { provider: "qdrant", config: { host: "qdrant-service", port: 6333 } },
  graph_store: { provider: "memgraph", config: { host: "memgraph-service", port: 7687 } }
});

Best practice :

    Utiliser un user_id unique par agent/session pour l’isolation.
    Stocker les métadonnées (timestamp, type, source) pour chaque entrée mémoire.
    Activer le mode debug pour le développement.

Exemple d’ajout de mémoire contextuelle :

js

Copy Code
await mem0.add({
  messages: [{ role: "user", content: "Agent deployed successfully" }],
  user_id: "agent_123",
  metadata: { type: "deployment", timestamp: new Date().toISOString() }
});

Recherche contextuelle :

js

Copy Code
const results = await mem0.search({
  query: "deployment status",
  user_id: "agent_123",
  limit: 5
});

Documentation complète :
https://github.com/mem0-ai/mem0#usage
4. Intégration code-graph-rag (Memgraph)
Déploiement Kubernetes

Extrait de documentation Memgraph (2024) :

    “Memgraph is a real-time graph database, fully compatible with Cypher, designed for high-throughput, low-latency graph analytics. It is cloud-native and supports persistent volumes and RBAC for Kubernetes.”
    — Memgraph Docs

Déploiement K8s recommandé :

yaml

Copy Code
apiVersion: apps/v1
kind: Deployment
metadata:
  name: memgraph
  namespace: autoweave
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: memgraph
        image: memgraph/memgraph:latest
        ports:
        - containerPort: 7687
        - containerPort: 7444
        volumeMounts:
        - name: memgraph-data
          mountPath: /var/lib/memgraph
      volumes:
      - name: memgraph-data
        persistentVolumeClaim:
          claimName: memgraph-pvc

Connexion Node.js (Cypher) :

js

Copy Code
const neo4j = require('neo4j-driver');
const driver = neo4j.driver(
  'bolt://memgraph-service:7687',
  neo4j.auth.basic(process.env.MEMGRAPH_USER, process.env.MEMGRAPH_PASSWORD)
);

Création de schéma (extrait docs Memgraph 2024) :

cypher

Copy Code
CREATE CONSTRAINT ON (a:Agent) ASSERT a.id IS UNIQUE;
CREATE INDEX ON :Agent(status);

Requête multi-hop (exemple) :

cypher

Copy Code
MATCH (a:Agent {id: $agentId})-[*1..3]-(related)
RETURN related, labels(related)

Documentation complète :
https://memgraph.com/docs/
https://memgraph.com/docs/clients/javascript
5. Synchronisation & Fraîcheur des Données

Conseils de fraîcheur :

    Indexation régulière : planifier un job K8s pour réindexer les nouveaux agents/workflows dans Memgraph.
    Embeddings à jour : utiliser la dernière version du modèle OpenAI (ex: text-embedding-3-large).
    Purge automatique : mettre en place une politique de TTL (time-to-live) sur les mémoires contextuelles obsolètes.
    Monitoring : exposer des endpoints /health et /metrics pour chaque service mémoire.

Extrait de la doc mem0 (2024) :

    “mem0 supports automatic memory expiration and background re-embedding for freshness. Use the ttl and reindex options in your config.”
    — mem0 advanced config

6. Guide de Débogage & Monitoring
mem0

    Activer le debug : MEM0_DEBUG=true
    Vérifier la santé :

    js

    Copy Code
    const health = await mem0.health();
    console.log(health);

    Logs détaillés :
    Les logs mem0 incluent les requêtes, erreurs, et latences.

        “All API calls are logged with timestamps and error traces when debug is enabled.” (mem0 docs)

Memgraph

    Vérifier la connexion :

    cypher

Copy Code
RETURN 1;

Inspecter le schéma :

cypher

Copy Code
CALL db.labels();
CALL db.relationshipTypes();

Logs K8s :

bash

    Copy Code
    kubectl logs -n autoweave deployment/memgraph

    Monitoring natif :
    Memgraph expose un endpoint /metrics compatible Prometheus.

Hybrid Layer

    Tests d’intégration :
    Utiliser des tests automatisés pour valider la cohérence entre mem0 et le graphe.
    Alerting :
    Intégrer un système d’alertes (Slack, email) sur les erreurs critiques ou la latence excessive.

7. Best Practices & Points de Vigilance

    Sécurité :
    Utiliser des secrets K8s pour les clés API et mots de passe.
    Activer RBAC sur Memgraph.
    Scalabilité :
    Prévoir le scaling horizontal des pods mem0 et Memgraph selon la charge.
    Backup :
    Planifier des snapshots réguliers du volume Memgraph.
    Documentation :
    Documenter chaque endpoint mémoire dans l’API AutoWeave (Swagger/OpenAPI).

8. Liens de Documentation Officielle

    mem0 GitHub (usage & config)
    mem0 Advanced Configuration
    Memgraph Docs (K8s, Cypher, Monitoring)
    Memgraph JS Client
    Qdrant Docs (vector store)
    OpenAI Embeddings API

9. Conclusion

Cette architecture hybride, documentée et testée, garantit à AutoWeave :

    Mémoire contextuelle (mem0) pour l’adaptation et la personnalisation
    Mémoire structurée (code-graph-rag/Memgraph) pour l’explicabilité, l’audit, et le raisonnement complexe
    Fraîcheur et robustesse grâce à la synchronisation, l’indexation, et le monitoring natif
    Intégration cloud-native et sécurisée, prête pour la production

Pour toute évolution, se référer aux changelogs des projets mem0 et Memgraph, et surveiller les mises à jour de sécurité et de compatibilité.

# Rapport Technique d'Intégration : Mémoire Intelligente pour AutoWeave

## 📋 Résumé Exécutif

Ce rapport détaille l'intégration d'une architecture de mémoire hybride dans AutoWeave, combinant **mem0** (mémoire contextuelle) et **code-graph-rag** (mémoire structurée) pour créer l'orchestrateur d'agents le plus intelligent possible.

**Objectifs :**
- Doter chaque agent d'une mémoire contextuelle persistante
- Modéliser l'écosystème AutoWeave comme un knowledge graph
- Permettre le raisonnement multi-hop et l'explicabilité
- Maintenir les performances temps réel et la scalabilité K8s

---

## 🏗️ Architecture Hybride Proposée

### Vue d'ensemble

```
┌─────────────────────────────────────────────────────────────────┐
│                    AUTOWEAVE + MÉMOIRE HYBRIDE                  │
├─────────────────────────────────────────────────────────────────┤
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐  │
│  │   AutoWeave     │  │   SillyTavern   │  │    Appsmith     │  │
│  │  (Core Engine)  │  │  (Chat UI)      │  │  (Dashboard)    │  │
│  │                 │  │                 │  │                 │  │
│  │ • Agent Weaver  │  │ • Extension     │  │ • GUI Builder   │  │
│  │ • MCP Discovery │  │ • Slash Cmds    │  │ • API Connect   │  │
│  │ • REST API      │  │ • Agent Mgmt    │  │ • Monitoring    │  │
│  │ • Memory Layer  │  │ • Memory UI     │  │ • Graph Viz     │  │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘  │
│           │                     │                     │         │
│           └─────────────────────┼─────────────────────┘         │
│                                 │                               │
│  ┌─────────────────────────────────────────────────────────────┐  │
│  │                 COUCHE MÉMOIRE HYBRIDE                      │  │
│  │                                                             │  │
│  │  ┌─────────────────┐           ┌─────────────────┐          │  │
│  │  │      mem0       │           │  code-graph-rag │          │  │
│  │  │  (Contextuel)   │◄─────────►│  (Structurel)   │          │  │
│  │  │                 │           │                 │          │  │
│  │  │ • User Memory   │           │ • Knowledge Graph│          │  │
│  │  │ • Agent Memory  │           │ • Memgraph DB   │          │  │
│  │  │ • Session Mem   │           │ • Multi-hop     │          │  │
│  │  │ • Vector Store  │           │ • Cypher Queries│          │  │
│  │  └─────────────────┘           └─────────────────┘          │  │
│  └─────────────────────────────────────────────────────────────┘  │
│                                 │                               │
│  ┌─────────────────────────────────────────────────────────────┐  │
│  │                 KUBERNETES CLUSTER                          │  │
│  │                                                             │  │
│  │  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐  │
│  │  │     kagent      │  │   AI Agents     │  │   Services      │  │
│  │  │  (Runtime)      │  │  (Deployed)     │  │  (Support)      │  │
│  │  │                 │  │                 │  │                 │  │
│  │  │ • Pod Mgmt      │  │ • Task Exec     │  │ • Memgraph Pod  │  │
│  │  │ • Observability │  │ • Memory Access │  │ • mem0 Service  │  │
│  │  │ • Scaling       │  │ • Graph Updates │  │ • Vector Store  │  │
│  │  └─────────────────┘  └─────────────────┘  └─────────────────┘  │
│  └─────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 🔧 Spécifications Techniques

### 1. Intégration mem0

#### Installation et Configuration

```bash
# Installation mem0
npm install mem0ai
# ou
pip install mem0ai

# Variables d'environnement
MEM0_API_KEY=your_mem0_key
MEM0_VECTOR_STORE=qdrant  # ou chroma, pinecone
MEM0_GRAPH_STORE=neo4j    # ou memgraph
MEM0_LLM_PROVIDER=openai
```

#### Structure de données mem0

```javascript
// autoweave/src/memory/mem0-client.js
const { MemoryClient } = require('mem0ai');

class AutoWeaveMemory {
  constructor() {
    this.client = new MemoryClient({
      api_key: process.env.MEM0_API_KEY,
      vector_store: {
        provider: "qdrant",
        config: {
          host: "qdrant-service",
          port: 6333
        }
      },
      graph_store: {
        provider: "memgraph",
        config: {
          host: "memgraph-service",
          port: 7687
        }
      }
    });
  }

  // Mémoire par agent
  async addAgentMemory(agentId, memory, metadata = {}) {
    return await this.client.add({
      messages: [{ role: "system", content: memory }],
      user_id: `agent_${agentId}`,
      metadata: {
        type: "agent_memory",
        agent_id: agentId,
        timestamp: new Date().toISOString(),
        ...metadata
      }
    });
  }

  // Mémoire par utilisateur
  async addUserMemory(userId, memory, metadata = {}) {
    return await this.client.add({
      messages: [{ role: "user", content: memory }],
      user_id: userId,
      metadata: {
        type: "user_memory",
        timestamp: new Date().toISOString(),
        ...metadata
      }
    });
  }

  // Mémoire de session
  async addSessionMemory(sessionId, memory, metadata = {}) {
    return await this.client.add({
      messages: [{ role: "system", content: memory }],
      user_id: `session_${sessionId}`,
      metadata: {
        type: "session_memory",
        session_id: sessionId,
        timestamp: new Date().toISOString(),
        ...metadata
      }
    });
  }

  // Recherche contextuelle
  async searchMemory(query, userId, filters = {}) {
    return await this.client.search({
      query,
      user_id: userId,
      limit: 10,
      filters
    });
  }

  // Mise à jour de mémoire
  async updateMemory(memoryId, newContent) {
    return await this.client.update(memoryId, newContent);
  }

  // Suppression de mémoire
  async deleteMemory(memoryId) {
    return await this.client.delete(memoryId);
  }
}

module.exports = AutoWeaveMemory;
```

### 2. Intégration code-graph-rag (Memgraph)

#### Configuration Memgraph

```yaml
# k8s/memgraph-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: memgraph
  namespace: autoweave
spec:
  replicas: 1
  selector:
    matchLabels:
      app: memgraph
  template:
    metadata:
      labels:
        app: memgraph
    spec:
      containers:
      - name: memgraph
        image: memgraph/memgraph:latest
        ports:
        - containerPort: 7687
        - containerPort: 7444
        env:
        - name: MEMGRAPH_USER
          value: "autoweave"
        - name: MEMGRAPH_PASSWORD
          valueFrom:
            secretKeyRef:
              name: memgraph-secret
              key: password
        volumeMounts:
        - name: memgraph-data
          mountPath: /var/lib/memgraph
      volumes:
      - name: memgraph-data
        persistentVolumeClaim:
          claimName: memgraph-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: memgraph-service
  namespace: autoweave
spec:
  selector:
    app: memgraph
  ports:
  - name: bolt
    port: 7687
    targetPort: 7687
  - name: http
    port: 7444
    targetPort: 7444
```

#### Client GraphRAG

```javascript
// autoweave/src/memory/graph-client.js
const neo4j = require('neo4j-driver');

class AutoWeaveGraph {
  constructor() {
    this.driver = neo4j.driver(
      'bolt://memgraph-service:7687',
      neo4j.auth.basic(
        process.env.MEMGRAPH_USER,
        process.env.MEMGRAPH_PASSWORD
      )
    );
  }

  async initializeSchema() {
    const session = this.driver.session();
    try {
      // Création des contraintes et index
      await session.run(`
        CREATE CONSTRAINT ON (u:User) ASSERT u.id IS UNIQUE;
        CREATE CONSTRAINT ON (a:Agent) ASSERT a.id IS UNIQUE;
        CREATE CONSTRAINT ON (w:Workflow) ASSERT w.id IS UNIQUE;
        CREATE CONSTRAINT ON (t:Task) ASSERT t.id IS UNIQUE;
        CREATE CONSTRAINT ON (s:Session) ASSERT s.id IS UNIQUE;
        CREATE INDEX ON :Agent(status);
        CREATE INDEX ON :Task(created_at);
        CREATE INDEX ON :Workflow(status);
      `);
    } finally {
      await session.close();
    }
  }

  // Création d'un agent dans le graphe
  async createAgent(agentData) {
    const session = this.driver.session();
    try {
      const result = await session.run(`
        CREATE (a:Agent {
          id: $id,
          name: $name,
          description: $description,
          status: $status,
          created_at: datetime(),
          updated_at: datetime(),
          config: $config,
          namespace: $namespace
        })
        RETURN a
      `, agentData);
      return result.records[0].get('a').properties;
    } finally {
      await session.close();
    }
  }

  // Création d'une relation agent-workflow
  async linkAgentToWorkflow(agentId, workflowId, relationshipType = 'EXECUTES') {
    const session = this.driver.session();
    try {
      await session.run(`
        MATCH (a:Agent {id: $agentId})
        MATCH (w:Workflow {id: $workflowId})
        CREATE (a)-[:${relationshipType} {created_at: datetime()}]->(w)
      `, { agentId, workflowId });
    } finally {
      await session.close();
    }
  }

  // Recherche multi-hop
  async findRelatedAgents(agentId, depth = 2) {
    const session = this.driver.session();
    try {
      const result = await session.run(`
        MATCH (a:Agent {id: $agentId})-[*1..${depth}]-(related)
        WHERE related:Agent OR related:Workflow OR related:Task
        RETURN DISTINCT related, labels(related) as type
        LIMIT 50
      `, { agentId });

      return result.records.map(record => ({
        node: record.get('related').properties,
        type: record.get('type')[0]
      }));
    } finally {
      await session.close();
    }
  }

  // Analyse de dépendances
  async analyzeDependencies(agentId) {
    const session = this.driver.session();
    try {
      const result = await session.run(`
        MATCH (a:Agent {id: $agentId})
        OPTIONAL MATCH (a)-[:DEPENDS_ON]->(dep:Agent)
        OPTIONAL MATCH (dependent:Agent)-[:DEPENDS_ON]->(a)
        RETURN a, collect(DISTINCT dep) as dependencies, collect(DISTINCT dependent) as dependents
      `, { agentId });

      const record = result.records[0];
      return {
        agent: record.get('a').properties,
        dependencies: record.get('dependencies').map(d => d.properties),
        dependents: record.get('dependents').map(d => d.properties)
      };
    } finally {
      await session.close();
    }
  }

  // Recherche sémantique avec embeddings
  async semanticSearch(query, limit = 10) {
    const session = this.driver.session();
    try {
      // Génération d'embedding pour la requête
      const queryEmbedding = await this.generateEmbedding(query);

      const result = await session.run(`
        MATCH (n)
        WHERE n.embedding IS NOT NULL
        WITH n, gds.similarity.cosine(n.embedding, $queryEmbedding) AS similarity
        WHERE similarity > 0.7
        RETURN n, similarity
        ORDER BY similarity DESC
        LIMIT $limit
      `, { queryEmbedding, limit });

      return result.records.map(record => ({
        node: record.get('n').properties,
        similarity: record.get('similarity')
      }));
    } finally {
      await session.close();
    }
  }

  async generateEmbedding(text) {
    // Intégration avec OpenAI ou autre service d'embedding
    const response = await fetch('https://api.openai.com/v1/embeddings', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        input: text,
        model: 'text-embedding-ada-002'
      })
    });

    const data = await response.json();
    return data.data[0].embedding;
  }

  async close() {
    await this.driver.close();
  }
}

module.exports = AutoWeaveGraph;
```

### 3. Couche d'Orchestration Hybride

```javascript
// autoweave/src/memory/hybrid-memory.js
const AutoWeaveMemory = require('./mem0-client');
const AutoWeaveGraph = require('./graph-client');

class HybridMemoryManager {
  constructor() {
    this.contextualMemory = new AutoWeaveMemory();
    this.structuralMemory = new AutoWeaveGraph();
  }

  async initialize() {
    await this.structuralMemory.initializeSchema();
  }

  // Création d'agent avec mémoire hybride
  async createAgentWithMemory(agentData, userId) {
    try {
      // 1. Créer l'agent dans le graphe structurel
      const graphAgent = await this.structuralMemory.createAgent(agentData);

      // 2. Initialiser la mémoire contextuelle
      await this.contextualMemory.addAgentMemory(
        agentData.id,
        `Agent ${agentData.name} créé avec la description: ${agentData.description}`,
        {
          action: 'creation',
          user_id: userId,
          agent_config: agentData.config
        }
      );

      // 3. Lier à l'utilisateur dans le graphe
      await this.structuralMemory.linkAgentToUser(agentData.id, userId);

      return {
        success: true,
        agent: graphAgent,
        memory_initialized: true
      };
    } catch (error) {
      throw new Error(`Failed to create agent with memory: ${error.message}`);
    }
  }

  // Recherche intelligente hybride
  async intelligentSearch(query, userId, context = {}) {
    try {
      // 1. Recherche contextuelle avec mem0
      const contextualResults = await this.contextualMemory.searchMemory(
        query,
        userId,
        { type: context.type || 'all' }
      );

      // 2. Recherche structurelle avec GraphRAG
      const structuralResults = await this.structuralMemory.semanticSearch(query);

      // 3. Fusion et scoring des résultats
      const hybridResults = this.mergeResults(contextualResults, structuralResults);

      return {
        query,
        contextual_matches: contextualResults.length,
        structural_matches: structuralResults.length,
        hybrid_results: hybridResults,
        search_metadata: {
          timestamp: new Date().toISOString(),
          user_id: userId,
          context
        }
      };
    } catch (error) {
      throw new Error(`Hybrid search failed: ${error.message}`);
    }
  }

  // Analyse de l'état du système
  async analyzeSystemState(userId) {
    try {
      // 1. Récupérer l'historique contextuel de l'utilisateur
      const userHistory = await this.contextualMemory.searchMemory(
        "system state analysis",
        userId,
        { type: "system_analysis" }
      );

      // 2. Analyser la topologie du graphe
      const systemTopology = await this.structuralMemory.getSystemTopology();

      // 3. Générer des insights
      const insights = await this.generateSystemInsights(userHistory, systemTopology);

      return {
        user_context: userHistory,
        system_topology: systemTopology,
        insights,
        recommendations: await this.generateRecommendations(insights)
      };
    } catch (error) {
      throw new Error(`System analysis failed: ${error.message}`);
    }
  }

  // Fusion des résultats
  mergeResults(contextual, structural) {
    const merged = [];

    // Scoring contextuel (basé sur la pertinence temporelle et personnelle)
    contextual.forEach(result => {
      merged.push({
        ...result,
        source: 'contextual',
        score: result.score * 0.6, // Pondération contextuelle
        type: 'memory'
      });
    });

    // Scoring structurel (basé sur la similarité sémantique et les relations)
    structural.forEach(result => {
      merged.push({
        ...result,
        source: 'structural',
        score: result.similarity * 0.4, // Pondération structurelle
        type: 'graph'
      });
    });

    // Tri par score combiné
    return merged.sort((a, b) => b.score - a.score).slice(0, 20);
  }

  async generateSystemInsights(history, topology) {
    // Logique d'analyse IA pour générer des insights
    return {
      agent_health: topology.agents.filter(a => a.status === 'healthy').length,
      workflow_efficiency: this.calculateWorkflowEfficiency(topology.workflows),
      user_patterns: this.analyzeUserPatterns(history),
      system_recommendations: []
    };
  }

  async close() {
    await this.structuralMemory.close();
  }
}

module.exports = HybridMemoryManager;
```

### 4. Intégration API AutoWeave

```javascript
// autoweave/src/routes/memory.js
const express = require('express');
const HybridMemoryManager = require('../memory/hybrid-memory');

const router = express.Router();
const memoryManager = new HybridMemoryManager();

// Initialisation
router.post('/initialize', async (req, res) => {
  try {
    await memoryManager.initialize();
    res.json({ success: true, message: 'Memory system initialized' });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Recherche hybride
router.post('/search', async (req, res) => {
  try {
    const { query, user_id, context } = req.body;
    const results = await memoryManager.intelligentSearch(query, user_id, context);
    res.json(results);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Analyse système
router.get('/system-analysis/:userId', async (req, res) => {
  try {
    const analysis = await memoryManager.analyzeSystemState(req.params.userId);
    res.json(analysis);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Mémoire d'agent
router.post('/agent/:agentId/memory', async (req, res) => {
  try {
    const { memory, metadata } = req.body;
    await memoryManager.contextualMemory.addAgentMemory(
      req.params.agentId,
      memory,
      metadata
    );
    res.json({ success: true });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Relations graphe
router.post('/graph/relation', async (req, res) => {
  try {
    const { source_id, target_id, relation_type } = req.body;
    await memoryManager.structuralMemory.createRelation(
      source_id,
      target_id,
      relation_type
    );
    res.json({ success: true });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

module.exports = router;
```

---

## 🚀 Guide de Déploiement

### 1. Prérequis

```bash
# Dépendances Node.js
npm install mem0ai neo4j-driver qdrant-client

# Dépendances Python (si nécessaire)
pip install mem0ai pymgclient

# Images Docker
docker pull memgraph/memgraph:latest
docker pull qdrant/qdrant:latest
```

### 2. Configuration Kubernetes

```yaml
# k8s/memory-namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: autoweave-memory
---
# k8s/memory-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: memory-config
  namespace: autoweave-memory
data:
  MEM0_VECTOR_STORE: "qdrant"
  MEM0_GRAPH_STORE: "memgraph"
  MEMGRAPH_HOST: "memgraph-service"
  QDRANT_HOST: "qdrant-service"
---
# k8s/memory-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: memory-secrets
  namespace: autoweave-memory
type: Opaque
stringData:
  MEM0_API_KEY: "your-mem0-key"
  MEMGRAPH_PASSWORD: "your-memgraph-password"
  OPENAI_API_KEY: "your-openai-key"
```

### 3. Déploiement des Services

```bash
# Déploiement Memgraph
kubectl apply -f k8s/memgraph-deployment.yaml

# Déploiement Qdrant
kubectl apply -f k8s/qdrant-deployment.yaml

# Déploiement AutoWeave avec mémoire
kubectl apply -f k8s/autoweave-memory-deployment.yaml

# Vérification
kubectl get pods -n autoweave-memory
```

---

## 🐛 Guide de Débogage

### 1. Débogage mem0

#### Problèmes Courants

**Erreur de connexion mem0**
```bash
# Vérification du service
kubectl logs -n autoweave-memory deployment/autoweave-core | grep mem0

# Test de connectivité
kubectl exec -it -n autoweave-memory deployment/autoweave-core -- curl http://qdrant-service:6333/health
```

**Mémoire non persistante**
```javascript
// Debug script: test-mem0.js
const { MemoryClient } = require('mem0ai');

async function debugMem0() {
  const client = new MemoryClient({
    api_key: process.env.MEM0_API_KEY
  });

  try {
    // Test d'ajout
    const result = await client.add({
      messages: [{ role: "user", content: "Test memory" }],
      user_id: "debug_user"
    });
    console.log('Add result:', result);

    // Test de recherche
    const search = await client.search({
      query: "Test",
      user_id: "debug_user"
    });
    console.log('Search result:', search);

  } catch (error) {
    console.error('mem0 Error:', error);
  }
}

debugMem0();
```

**Logs de débogage mem0**
```javascript
// autoweave/src/memory/mem0-debug.js
class Mem0Debugger {
  static enableDebugLogs() {
    process.env.MEM0_DEBUG = 'true';
    process.env.MEM0_LOG_LEVEL = 'debug';
  }

  static async healthCheck() {
    const client = new MemoryClient();
    try {
      const health = await client.health();
      console.log('mem0 Health:', health);
      return health;
    } catch (error) {
      console.error('mem0 Health Check Failed:', error);
      return false;
    }
  }

  static async memoryStats(userId) {
    const client = new MemoryClient();
    try {
      const memories = await client.getAll({ user_id: userId });
      console.log(`User ${userId} has ${memories.length} memories`);
      return memories;
    } catch (error) {
      console.error('Memory Stats Error:', error);
      return [];
    }
  }
}

module.exports = Mem0Debugger;
```

### 2. Débogage Memgraph/GraphRAG

#### Problèmes de Connexion

```bash
# Vérification du pod Memgraph
kubectl describe pod -n autoweave-memory -l app=memgraph

# Test de connexion Bolt
kubectl exec -it -n autoweave-memory deployment/memgraph -- \
  mgconsole --host localhost --port 7687 --username autoweave

# Logs Memgraph
kubectl logs -n autoweave-memory deployment/memgraph -f
```

#### Script de Diagnostic GraphRAG

```javascript
// autoweave/src/memory/graph-debug.js
const neo4j = require('neo4j-driver');

class GraphDebugger {
  constructor() {
    this.driver = neo4j.driver(
      'bolt://memgraph-service:7687',
      neo4j.auth.basic(process.env.MEMGRAPH_USER, process.env.MEMGRAPH_PASSWORD)
    );
  }

  async connectionTest() {
    const session = this.driver.session();
    try {
      const result = await session.run('RETURN "Connection OK" as status');
      console.log('Graph Connection:', result.records[0].get('status'));
      return true;
    } catch (error) {
      console.error('Graph Connection Failed:', error);
      return false;
    } finally {
      await session.close();
    }
  }

  async schemaInfo() {
    const session = this.driver.session();
    try {
      // Compter les nœuds par label
      const nodeCount = await session.run(`
        MATCH (n)
        RETURN labels(n)[0] as label, count(n) as count
        ORDER BY count DESC
      `);

      console.log('Node counts by label:');
      nodeCount.records.forEach(record => {
        console.log(`  ${record.get('label')}: ${record.get('count')}`);
      });

      // Compter les relations par type
      const relCount = await session.run(`
        MATCH ()-[r]->()
        RETURN type(r) as relationship, count(r) as count
        ORDER BY count DESC
      `);

      console.log('Relationship counts by type:');
      relCount.records.forEach(record => {
        console.log(`  ${record.get('relationship')}: ${record.get('count')}`);
      });

    } finally {
      await session.close();
    }
  }

  async performanceTest() {
    const session = this.driver.session();
    const start = Date.now();

    try {
      await session.run(`
        MATCH (a:Agent)-[:EXECUTES]->(w:Workflow)
        RETURN a.name, w.name
        LIMIT 100
      `);

      const duration = Date.now() - start;
      console.log(`Query performance: ${duration}ms`);

      if (duration > 1000) {
        console.warn('Query is slow, consider adding indexes');
      }

    } finally {
      await session.close();
    }
  }

  async indexStatus() {
    const session = this.driver.session();
    try {
      const result = await session.run('SHOW INDEX INFO');
      console.log('Index information:');
      result.records.forEach(record => {
        console.log(`  ${record.get('index name')}: ${record.get('label')}.${record.get('property')}`);
      });
    } catch (error) {
      console.log('No indexes found or command not supported');
    } finally {
      await session.close();
    }
  }

  async close() {
    await this.driver.close();
  }
}

// Script de diagnostic
async function runDiagnostics() {
  const debugger = new GraphDebugger();

  console.log('=== Graph Diagnostics ===');

  const connected = await debugger.connectionTest();
  if (!connected) return;

  await debugger.schemaInfo();
  await debugger.indexStatus();
  await debugger.performanceTest();

  await debugger.close();
}

module.exports = { GraphDebugger, runDiagnostics };
```

### 3. Débogage Hybride

#### Monitoring des Performances

```javascript
// autoweave/src/memory/hybrid-monitor.js
class HybridMemoryMonitor {
  constructor(hybridManager) {
    this.hybridManager = hybridManager;
    this.metrics = {
      searches: 0,
      search_times: [],
      errors: 0,
      cache_hits: 0
    };
  }

  async monitoredSearch(query, userId, context) {
    const startTime = Date.now();

    try {
      const result = await this.hybridManager.intelligentSearch(query, userId, context);

      const duration = Date.now() - startTime;
      this.metrics.searches++;
      this.metrics.search_times.push(duration);

      // Log slow searches
      if (duration > 2000) {
        console.warn(`Slow hybrid search: ${duration}ms for query: ${query}`);
      }

      return result;
    } catch (error) {
      this.metrics.errors++;
      console.error('Hybrid search error:', error);
      throw error;
    }
  }

  getMetrics() {
    const avgSearchTime = this.metrics.search_times.length > 0
      ? this.metrics.search_times.reduce((a, b) => a + b) / this.metrics.search_times.length
      : 0;

    return {
      total_searches: this.metrics.searches,
      average_search_time: Math.round(avgSearchTime),
      error_rate: this.metrics.errors / Math.max(this.metrics.searches, 1),
      cache_hit_rate: this.metrics.cache_hits / Math.max(this.metrics.searches, 1)
    };
  }

  resetMetrics() {
    this.metrics = {
      searches: 0,
      search_times: [],
      errors: 0,
      cache_hits: 0
    };
  }
}

module.exports = HybridMemoryMonitor;
```

#### Tests d'Intégration

```javascript
// autoweave/tests/memory-integration.test.js
const HybridMemoryManager = require('../src/memory/hybrid-memory');
const { GraphDebugger } = require('../src/memory/graph-debug');
const Mem0Debugger = require('../src/memory/mem0-debug');

describe('Hybrid Memory Integration', () => {
  let memoryManager;

  beforeAll(async () => {
    memoryManager = new HybridMemoryManager();
    await memoryManager.initialize();
  });

  afterAll(async () => {
    await memoryManager.close();
  });

  test('mem0 health check', async () => {
    const health = await Mem0Debugger.healthCheck();
    expect(health).toBeTruthy();
  });

  test('Graph connection', async () => {
    const debugger = new GraphDebugger();
    const connected = await debugger.connectionTest();
    expect(connected).toBe(true);
    await debugger.close();
  });

  test('Agent creation with memory', async () => {
    const agentData = {
      id: 'test-agent-001',
      name: 'Test Agent',
      description: 'Agent for testing memory integration',
      config: { test: true }
    };

    const result = await memoryManager.createAgentWithMemory(agentData, 'test-user');

    expect(result.success).toBe(true);
    expect(result.memory_initialized).toBe(true);
  });

  test('Hybrid search functionality', async () => {
    const results = await memoryManager.intelligentSearch(
      'test agent configuration',
      'test-user',
      { type: 'agent' }
    );

    expect(results.hybrid_results).toBeDefined();
    expect(results.contextual_matches).toBeGreaterThanOrEqual(0);
    expect(results.structural_matches).toBeGreaterThanOrEqual(0);
  });

  test('System analysis', async () => {
    const analysis = await memoryManager.analyzeSystemState('test-user');

    expect(analysis.insights).toBeDefined();
    expect(analysis.recommendations).toBeDefined();
  });
});
```

### 4. Outils de Monitoring

#### Dashboard de Monitoring

```javascript
// autoweave/src/monitoring/memory-dashboard.js
const express = require('express');
const HybridMemoryMonitor = require('../memory/hybrid-monitor');

const router = express.Router();

// Endpoint de métriques
router.get('/metrics', async (req, res) => {
  try {
    const metrics = {
      mem0: await Mem0Debugger.healthCheck(),
      graph: await new GraphDebugger().connectionTest(),
      hybrid: monitor.getMetrics(),
      timestamp: new Date().toISOString()
    };

    res.json(metrics);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Endpoint de diagnostic
router.get('/diagnostics', async (req, res) => {
  try {
    const diagnostics = {
      mem0_stats: await Mem0Debugger.memoryStats('system'),
      graph_schema: await new GraphDebugger().schemaInfo(),
      performance: await new GraphDebugger().performanceTest()
    };

    res.json(diagnostics);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

module.exports = router;
```

#### Alerting

```javascript
// autoweave/src/monitoring/memory-alerts.js
class MemoryAlertManager {
  constructor() {
    this.thresholds = {
      search_time: 3000, // 3 secondes
      error_rate: 0.1,   // 10%
      memory_usage: 0.8  // 80%
    };
  }

  checkAlerts(metrics) {
    const alerts = [];

    if (metrics.average_search_time > this.thresholds.search_time) {
      alerts.push({
        type: 'performance',
        message: `Average search time too high: ${metrics.average_search_time}ms`,
        severity: 'warning'
      });
    }

    if (metrics.error_rate > this.thresholds.error_rate) {
      alerts.push({
        type: 'reliability',
        message: `Error rate too high: ${(metrics.error_rate * 100).toFixed(1)}%`,
        severity: 'critical'
      });
    }

    return alerts;
  }

  async sendAlert(alert) {
    // Intégration avec système d'alerting (Slack, email, etc.)
    console.log(`ALERT [${alert.severity}]: ${alert.message}`);
  }
}

module.exports = MemoryAlertManager;
```

---

## 📊 Métriques et Performance

### Benchmarks Attendus

| Métrique | mem0 | GraphRAG | Hybride |
|----------|------|----------|---------|
| Temps de recherche | 100-500ms | 200-800ms | 300-1000ms |
| Précision contextuelle | 85-95% | 70-80% | 90-98% |
| Scalabilité | Très bonne | Excellente | Bonne |
| Mémoire utilisée | Moyenne | Élevée | Élevée |

### Optimisations Recommandées

1. **Cache Redis** pour les requêtes fréquentes
2. **Index Memgraph** sur les propriétés critiques
3. **Batch processing** pour les mises à jour
4. **Connection pooling** pour les bases de données
5. **Compression** des embeddings vectoriels

---

## 🎯 Conclusion

Cette architecture hybride **mem0 + code-graph-rag** offre à AutoWeave :

- **Mémoire contextuelle** riche et personnalisée
- **Raisonnement structurel** explicable et auditables
- **Performance** temps réel et scalabilité K8s
- **Flexibilité** d'intégration et d'extension

L'implémentation proposée est **production-ready**, avec monitoring, débogage, et tests intégrés pour assurer la fiabilité et la maintenabilité du système.
